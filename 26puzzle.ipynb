{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcebf316-d4cd-4345-ac36-d69907f636b9",
   "metadata": {},
   "source": [
    "## Class Puzzle \n",
    "Class Puzzle encapsulates reading of input file, storing the values of start and goal grids in numpy arrays and defining the set of actions possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de8db2d-8477-4b4a-8998-a2811b6e4165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import heapq\n",
    "\n",
    "#Class puzzle will contain the functions required to initialise our puzzle grid, goal grid and actions. \n",
    "#We are currently treating the size to be variable and it will work for a larger puzzle as well, the value \\\n",
    "#of 3 is given in main\n",
    "class Puzzle:\n",
    "    def __init__(self, input_file, size):\n",
    "        self.size = size\n",
    "        self.startgrid = np.zeros((self.size, self.size, self.size), dtype=int)\n",
    "        self.goalgrid = np.zeros((self.size, self.size, self.size), dtype=int)\n",
    "        self.actions = ['N','E','W','S','U','D']\n",
    "        self.load_puzzle(input_file)\n",
    "        \n",
    "    #Loads the startgrid and goalgrid arrays by reading the input file\n",
    "    def load_puzzle(self, input_file):\n",
    "        with open(input_file, 'r') as file:\n",
    "            # Read the entire file content into a string\n",
    "            self.file_content = file.read().strip()\n",
    "\n",
    "        #We split by double EOL to get each 3x3 layer of the puzzle\n",
    "        layers = self.file_content.split('\\n\\n')\n",
    "\n",
    "        #We get line by line and thereafter space separated numbers to fill into the arrays\n",
    "        for i in range(self.size):\n",
    "            lines = layers[:self.size][i].split('\\n')\n",
    "            for j in range(self.size):\n",
    "                nums = lines[j].split(' ') \n",
    "                for k in range(self.size):\n",
    "                    self.startgrid[i][j][k] = nums[k]\n",
    "\n",
    "        for i in range(self.size):\n",
    "            lines = layers[self.size:][i].split('\\n')\n",
    "            for j in range(self.size):\n",
    "                nums = lines[j].split(' ') \n",
    "                for k in range(self.size):\n",
    "                    self.goalgrid[i][j][k] = nums[k]\n",
    "\n",
    "    #Prints the input file as such, as defined in the output format\n",
    "    def print_start_and_goal_grid(self):\n",
    "        print(self.file_content)\n",
    "\n",
    "    #Prints the input file as such, to a defined output file f\n",
    "    def print_to_file(self, f):\n",
    "        print(self.file_content, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2a65ec-1fb2-4787-b82f-f74154fcb9c0",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0caa83b3-c44f-4d70-a1e0-6f40ce0e98fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate manhattan distance by adding absolute value of difference in i, j and k\n",
    "def manhat_distance(cur_state, goal_state):\n",
    "    manhat_dist = 0\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            for k in range(size):\n",
    "                i2, j2, k2 = np.argwhere(cur_state == goal_state[i, j, k])[0]\n",
    "                if(goal_state[i, j, k]!=0):\n",
    "                    manhat_dist += abs(i-i2)+abs(j-j2)+abs(k-k2)\n",
    "    return manhat_dist\n",
    "\n",
    "#Computes what the next state will be based on current state and what action is performed \n",
    "def compute_next_state(cur_state, action):\n",
    "    i, j, k = np.argwhere(cur_state == 0)[0]\n",
    "    i2, j2, k2 = i, j, k\n",
    "    if(action == 'N'):\n",
    "        j2 = j-1\n",
    "    if(action == 'S'):\n",
    "        j2 = j+1\n",
    "    if(action == 'W'):\n",
    "        k2 = k-1\n",
    "    if(action == 'E'):\n",
    "        k2 = k+1        \n",
    "    if(action == 'U'):\n",
    "        i2 = i-1\n",
    "    if(action == 'D'):\n",
    "        i2 = i+1  \n",
    "\n",
    "    #Handling edge cases with if condition to avoid invalid actions\n",
    "    if(i2<size and i2>=0 and j2<size and j2>=0 and k2<size and k2>=0):\n",
    "        #We create a copy to avoid overwriting, as list would be passed by reference\n",
    "        next_state = np.copy(cur_state)    \n",
    "        # Swap the values\n",
    "        next_state[i, j, k], next_state[i2, j2, k2] = next_state[i2, j2, k2], next_state[i, j, k]\n",
    "        return next_state\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#This generator will generate a monotonically increasing counter everytime it gets called. \n",
    "#It is called everytime we generate a new node.\n",
    "#This will be the second value in priority queues' sorting key, to pick the older element first, \n",
    "#once multiple states have same priority(f-value) and thereby break the tie. \n",
    "def monotonically_increasing_generator():\n",
    "    current_value = 0\n",
    "    while True:\n",
    "        current_value += 1\n",
    "        yield current_value\n",
    "\n",
    "#This is the function that searches for goal state using A* algorithm with the heuristic\n",
    "#f(node) = manhattan_distance(node,goal) + distance(start,node)\n",
    "def solve(start_state, goal_state, actions):\n",
    "    frontier = [] \n",
    "    visited = [tuple(start_state.ravel())]\n",
    "    mono_gen = monotonically_increasing_generator()\n",
    "    \n",
    "    start_dist = manhat_distance(start_state, goal_state)\n",
    "    \n",
    "    start_node = (start_dist, next(mono_gen), start_state, 0, [], [start_dist])\n",
    "    heapq.heappush(frontier, start_node)\n",
    "    #boolean variable to check if we have reached a goal state\n",
    "    found = False\n",
    "    while(frontier):\n",
    "        #We use this heapq to maintain out priority queue. Node contains details about the state,\n",
    "        #the actions taken to reach till there, the value of f (distance)\n",
    "        cur_node = heapq.heappop(frontier)\n",
    "        \n",
    "        cur_state,  cur_depth, cur_actionpath, cur_dist_list = cur_node[2:6]\n",
    "\n",
    "        #If we reach a goal we return the node and the number of nodes generated and halt the iteration\n",
    "        if np.array_equal(cur_state, goal_state):\n",
    "            found = True\n",
    "            #Here next(mono_gen)-1 will give the output as the total number of nodes generated\n",
    "            return cur_node, next(mono_gen)-1 \n",
    "\n",
    "        #Here we generate child nodes for every node expanded\n",
    "        for action in actions:\n",
    "            #First compute the set of next states based on actions\n",
    "            next_state = compute_next_state(cur_state, action)\n",
    "\n",
    "            #Check if the action would have led to a valid state\n",
    "            if next_state is not None:\n",
    "                #We flatten the 3D arr and convert to tuple as np array cannot be used for direct comparison\n",
    "                next_state_tuple = tuple(next_state.ravel())\n",
    "                #We check if the state has been reached previously and avoid if yes, as it is graph search\n",
    "                if next_state_tuple not in visited:\n",
    "                    visited.append(next_state_tuple)\n",
    "                    depth = cur_depth + 1 \n",
    "                    \n",
    "                    #Calculating f(node) = manhattan_distance(node,goal) + distance(start,node)\n",
    "                    dist = manhat_distance(next_state, goal_state) + depth  \n",
    "                    dist_list = cur_dist_list[:]\n",
    "                    dist_list.append(dist)\n",
    "\n",
    "                    #Compute action path by taking parent's actionpath and appending the current action\n",
    "                    actionpath = cur_actionpath[:]\n",
    "                    actionpath.append(action)\n",
    "\n",
    "                    #Node is generated with its distance(priority key), counter, state, depth, actionpath\n",
    "                    #and distance list\n",
    "                    #We use monotonic generator to handle cases with same priority, priority will be \n",
    "                    #given to older entries in the priority queue. We prioritise by distance.\n",
    "                    next_node = (dist, next(mono_gen), next_state, depth, actionpath, dist_list)\n",
    "                    \n",
    "                    #Push the child into the priority queue with given information\n",
    "                    heapq.heappush(frontier, next_node)\n",
    "\n",
    "    if(found == False):\n",
    "        print(\"No solution exists\")\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8675c651-c426-41cd-9427-c7d9110e9301",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3e0039f-92ef-4ea1-b4bf-0b6b8a215226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n",
      "4 0 5\n",
      "6 7 8\n",
      "\n",
      "9 10 11\n",
      "12 13 14\n",
      "15 16 17\n",
      "\n",
      "18 19 20\n",
      "21 22 23\n",
      "24 25 26\n",
      "\n",
      "1 2 3\n",
      "4 13 5\n",
      "6 7 8\n",
      "\n",
      "9 10 11\n",
      "15 12 14\n",
      "24 16 17\n",
      "\n",
      "18 19 20\n",
      "21 0 23\n",
      "25 22 26\n",
      "\n",
      "6\n",
      "23\n",
      "D W S D E N\n",
      "6 6 6 6 6 6 6\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    size = 3\n",
    "    input = 'input1.txt'\n",
    "    output = 'output1.txt'\n",
    "    #Initialise puzzle object with contents from the input file\n",
    "    puzzle = Puzzle(input, size)\n",
    "\n",
    "    #solve function takes the start state, goal state and actions to search and return goal node \n",
    "    #containing all the meta info about the search and number of nodes generated\n",
    "    goal_node, num_gen_nodes = solve(puzzle.startgrid, puzzle.goalgrid, puzzle.actions)\n",
    "\n",
    "    #Retrieving depth, action path and list of distances from goal node\n",
    "    depth_goal_node = goal_node[3]\n",
    "    actionpath_goal_node = ' '.join(goal_node[4])\n",
    "    distlist_goal_node = ' '.join(map(str, goal_node[5])) \n",
    "    \n",
    "    #Outputs\n",
    "    puzzle.print_start_and_goal_grid()\n",
    "    print(\"\", depth_goal_node, num_gen_nodes, actionpath_goal_node, distlist_goal_node, sep='\\n')\n",
    "\n",
    "    #Write the ouputs to a file\n",
    "    with open(output, 'w') as f:\n",
    "        # Redirect the last two print statements to the file\n",
    "        puzzle.print_to_file(f)\n",
    "        print(\"\", depth_goal_node, num_gen_nodes, actionpath_goal_node, distlist_goal_node, sep='\\n', file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
